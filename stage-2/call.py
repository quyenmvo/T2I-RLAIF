import json
import requests
import base64
from PIL import Image
from io import BytesIO
import time
import os
import sys
import shutil
from numpy.random import randint

LLAVA_URL = 'http://localhost:11434/api/generate'
LLAVA_13B_MODEL = 'llava:13b'
LLAVA_7B_MODEL = 'llava:7b'

def getImageFromSD(prompt, SD_URL):
    """
    Retrieves a base64 image from stable diffusion local server based on the provided prompt. 

    Parameters:
    - prompt (str): The user prompt/description to be used as input to generate image.
    
    Returns:
    - str (base 64 encoded): The image generated encoded to base 64.
    """
    start_time = time.time()
        
    sdRequestBody = {'prompt': prompt}
    sdResponse = requests.post(SD_URL, data=sdRequestBody)
    image = sdResponse.json()['image']
    
    process_time = time.time() - start_time

    return image, process_time

def getResponeFromLLaVA13b(target, image=None):
    """
    Retrieves a response from the LLaVa 13b multimodal model based on the provided target prompt and optional image. 

    Parameters:
    - target (str): The user prompt to be used as input to the model. It typically includes a request for evaluation along with a description.
    - image (str, optional): A base64 encoded image to be evaluated alongside the target prompt. If provided, the model will assess whether the image aligns with the description in the target.

    Returns:
    - str: A response generated by the model, indicating its evaluation based on the input target prompt and image.
    """
    if image:
        llavaRequestBody = {
            'model': LLAVA_13B_MODEL, 
            'prompt': target, # string
            'images': [image] # base64 string
        }
        message = "[Evaluating]"
        
    else:
        llavaRequestBody = {
            'model': LLAVA_13B_MODEL, 
            'prompt': target, # string
        }
        message = "[Improving prompt]"
        
        
    return_prompt = ""

    print(f"\t{message}...")
    start_time = time.time()
        
    llavaResponse = requests.post(LLAVA_URL, data=json.dumps(llavaRequestBody))
    # print(llavaResponse.text)
        
    for line in llavaResponse.iter_lines():
        if line:  # filter out keep-alive new lines
            # print('[LINE]', line)
            json_line = json.loads(line.decode('utf-8'))
            if 'response' in json_line:
                return_prompt += json_line['response']
        
    llavaResultMessage = return_prompt.strip()
    process_time = time.time() - start_time
    print(f"\t[Result] in {process_time:0.1f} secs: ", llavaResultMessage)
    return llavaResultMessage, process_time


def getResponeFromLLaVA7b(target, image=None):
    """
    Retrieves a response from the LLaVa 7b multimodal model based on the provided target prompt and optional image. 

    Parameters:
    - target (str): The user prompt to be used as input to the model. It typically includes a request for evaluation along with a description.
    - image (str, optional): A base64 encoded image to be evaluated alongside the target prompt. If provided, the model will assess whether the image aligns with the description in the target.

    Returns:
    - str: A response generated by the model, indicating its evaluation based on the input target prompt and image.
    """
    if image:
        llavaRequestBody = {
            'model': LLAVA_7B_MODEL, 
            'prompt': target, # string
            'images': [image] # base64 string
        }
        message = "[Evaluating]"
        
    else:
        llavaRequestBody = {
            'model': LLAVA_7B_MODEL, 
            'prompt': target, # string
        }
        message = "[Improving prompt]"
        
        
    return_prompt = ""

    print(f"\t{message}...")
    start_time = time.time()
        
    llavaResponse = requests.post(LLAVA_URL, data=json.dumps(llavaRequestBody))
    # print(llavaResponse.text)
        
    for line in llavaResponse.iter_lines():
        if line:  # filter out keep-alive new lines
            # print('[LINE]', line)
            json_line = json.loads(line.decode('utf-8'))
            if 'response' in json_line:
                return_prompt += json_line['response']
        
    llavaResultMessage = return_prompt.strip()
    process_time = time.time() - start_time
    print(f"\t[Result] in {process_time:0.1f} secs: ", llavaResultMessage)
    return llavaResultMessage, process_time

